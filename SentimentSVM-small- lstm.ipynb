{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"Y:/GP/Datasets/Emotion datasets/archive/train.txt\",delimiter=';',names=['text','label'])\n",
    "df_val = pd.read_csv(\"Y:/GP/Datasets/Emotion datasets/archive/val.txt\",delimiter=';',names=['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: (18000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17477</th>\n",
       "      <td>i had finished my first leg the toughest longe...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>i feel truly blessed to have had the opportuni...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15484</th>\n",
       "      <td>i should ask them to move but the movers were ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7573</th>\n",
       "      <td>i know it signifies him feeling not dangerous ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6641</th>\n",
       "      <td>i feel like there is so much more i could be d...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "17477  i had finished my first leg the toughest longe...   love\n",
       "2982   i feel truly blessed to have had the opportuni...   love\n",
       "15484  i should ask them to move but the movers were ...  anger\n",
       "7573   i know it signifies him feeling not dangerous ...  anger\n",
       "6641   i feel like there is so much more i could be d...   love"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_train,df_val])\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "print(\"Shape of the DataFrame:\",df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_encoder(df):\n",
    "    df.replace(to_replace =\"surprise\", value =1, inplace=True)\n",
    "    df.replace(to_replace =\"love\", value =1, inplace=True)\n",
    "    df.replace(to_replace =\"joy\", value =1, inplace=True)\n",
    "    df.replace(to_replace =\"fear\", value =0, inplace=True)\n",
    "    df.replace(to_replace =\"anger\", value =0, inplace=True)\n",
    "    df.replace(to_replace =\"sadness\", value =0, inplace=True)\n",
    "\n",
    "custom_encoder(df['label'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16871</th>\n",
       "      <td>i feel sure is greater to those who are not da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "16871  i feel sure is greater to those who are not da...      1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16197"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_vectors.shape\n",
    "encoded_docs = tokenizer.texts_to_sequences(df['text'])\n",
    "\n",
    "padded_sequence = pad_sequences(encoded_docs, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "\n",
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_length, input_length=200))\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "225/225 [==============================] - 34s 142ms/step - loss: 0.6163 - accuracy: 0.6421 - val_loss: 0.4226 - val_accuracy: 0.8344\n",
      "Epoch 2/15\n",
      "225/225 [==============================] - 31s 138ms/step - loss: 0.2519 - accuracy: 0.9076 - val_loss: 0.1796 - val_accuracy: 0.9378\n",
      "Epoch 3/15\n",
      "225/225 [==============================] - 32s 140ms/step - loss: 0.1416 - accuracy: 0.9494 - val_loss: 0.1572 - val_accuracy: 0.9461\n",
      "Epoch 4/15\n",
      "225/225 [==============================] - 32s 140ms/step - loss: 0.0874 - accuracy: 0.9685 - val_loss: 0.1625 - val_accuracy: 0.9439\n",
      "Epoch 5/15\n",
      "225/225 [==============================] - 32s 141ms/step - loss: 0.0708 - accuracy: 0.9758 - val_loss: 0.1577 - val_accuracy: 0.9478\n",
      "Epoch 6/15\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.0580 - accuracy: 0.9803 - val_loss: 0.1723 - val_accuracy: 0.9469\n",
      "Epoch 7/15\n",
      "225/225 [==============================] - 32s 141ms/step - loss: 0.0503 - accuracy: 0.9830 - val_loss: 0.1707 - val_accuracy: 0.9481\n",
      "Epoch 8/15\n",
      "225/225 [==============================] - 33s 147ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.1728 - val_accuracy: 0.9478\n",
      "Epoch 9/15\n",
      "225/225 [==============================] - 33s 145ms/step - loss: 0.0350 - accuracy: 0.9872 - val_loss: 0.1834 - val_accuracy: 0.9422\n",
      "Epoch 10/15\n",
      "225/225 [==============================] - 31s 136ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.2491 - val_accuracy: 0.9067\n",
      "Epoch 11/15\n",
      "225/225 [==============================] - 31s 136ms/step - loss: 0.0435 - accuracy: 0.9844 - val_loss: 0.1770 - val_accuracy: 0.9475\n",
      "Epoch 12/15\n",
      "225/225 [==============================] - 34s 151ms/step - loss: 0.0326 - accuracy: 0.9883 - val_loss: 0.1724 - val_accuracy: 0.9508\n",
      "Epoch 13/15\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.1898 - val_accuracy: 0.9517\n",
      "Epoch 14/15\n",
      "225/225 [==============================] - 36s 162ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.2103 - val_accuracy: 0.9458\n",
      "Epoch 15/15\n",
      "225/225 [==============================] - 37s 164ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.2239 - val_accuracy: 0.9456\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(padded_sequence,df['label'],validation_split=0.2, epochs=15, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "    \n",
    "model.save('sentimentAnalysisSmallLSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    tw = tokenizer.texts_to_sequences([text])\n",
    "    print(tw)\n",
    "    tw = pad_sequences(tw,maxlen=200)\n",
    "    print(tw)\n",
    "    prediction = int(model.predict(tw).round().item())\n",
    "    print(\"Predicted label: \", prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1746, 1887]]\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1 1746 1887]]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predicted label:  0\n"
     ]
    }
   ],
   "source": [
    "# predict_sentiment('I cried alot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer2=Tokenizer()\n",
    "# tokenizer2.fit_on_texts(df['text'])\n",
    "# loaded_model = load_model('sentimentAnalysisSmallLSTM.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 13, 975]]\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   2\n",
      "   13 975]]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predicted label:  1\n"
     ]
    }
   ],
   "source": [
    "# tw = tokenizer2.texts_to_sequences(['i feel like crying'])\n",
    "# print(tw)\n",
    "# tw = pad_sequences(tw,maxlen=200)\n",
    "# print(tw)\n",
    "# prediction = int(loaded_model.predict(tw).round().item())\n",
    "# print(\"Predicted label: \", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer# Create feature vectors\n",
    "# vectorizer = TfidfVectorizer(min_df = 5,\n",
    "#                              max_df = 0.8,\n",
    "#                              sublinear_tf = True,\n",
    "#                              use_idf = True)\n",
    "# train_vectors = vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df =  pd.read_csv(\"Y:/GP/Datasets/Emotion datasets/archive/test.txt\",delimiter=';',names=['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test,y_test = test_df.text,test_df.label\n",
    "# # encode the labels into two classes , 0 and 1\n",
    "# custom_encoder(y_test)\n",
    "\n",
    "\n",
    "# test_vectors = vectorizer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,classification_report,plot_confusion_matrix,ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# # from sklearn.metrics import classification_report# Perform classification with SVM, kernel=linear\n",
    "# classifier_linear = svm.SVC(kernel='linear')\n",
    "# classifier_linear.fit(train_vectors, df['label'])\n",
    "# prediction_linear = classifier_linear.predict(test_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32my:\\GP\\TextSentimentAnalysis\\SentimentSVM-small- lstm.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/y%3A/GP/TextSentimentAnalysis/SentimentSVM-small-%20lstm.ipynb#ch0000018?line=0'>1</a>\u001b[0m report \u001b[39m=\u001b[39m classification_report(y_test, prediction_linear, output_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/y%3A/GP/TextSentimentAnalysis/SentimentSVM-small-%20lstm.ipynb#ch0000018?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mpositive: \u001b[39m\u001b[39m'\u001b[39m, report[\u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/y%3A/GP/TextSentimentAnalysis/SentimentSVM-small-%20lstm.ipynb#ch0000018?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnegative: \u001b[39m\u001b[39m'\u001b[39m, report[\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, prediction_linear, output_dict=True)\n",
    "print('positive: ', report['1'])\n",
    "print('negative: ', report['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(y_test,prediction_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score:  0.9735\n",
      "Precision_score:  0.9737704918032787\n",
      "Recall_score:  0.9684782608695652\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      1080\n",
      "           1       0.97      0.97      0.97       920\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction_linear=logisticPrediction\n",
    "acc_score = accuracy_score(y_test,prediction_linear)\n",
    "pre_score = precision_score(y_test,prediction_linear)\n",
    "rec_score = recall_score(y_test,prediction_linear)\n",
    "print('Accuracy_score: ',acc_score)\n",
    "print('Precision_score: ',pre_score)\n",
    "print('Recall_score: ',rec_score)\n",
    "print(\"-\"*50)\n",
    "cr = classification_report(y_test,prediction_linear)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM linear : 97.35 .\n",
    "\n",
    "svm rbf : 96.85.\n",
    "\n",
    "svm sigmoid : 97.05.\n",
    "\n",
    "Logistic Regression: 95.7.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a76cc94cdb2ea0e3d4b4b62890ac8be9dbe5f144a88cb508caf3e8ff4445435"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
